{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce with mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =[]\n",
    "with open('yelp_review_subset.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textfalse = ''\n",
    "for x in data:\n",
    "    if x['review_id'] == \"xq1Y9AFMEKFEmqhAJDS_Gw\":\n",
    "        textfalse = ((x['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "textright = ''\n",
    "for x in data:\n",
    "    if x['review_id'] == \"6O1CBD0c9Zm7siaK22vibA\":\n",
    "        textright = ((x['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setfalse = {}\n",
    "textfalse = ''.join(textfalse.split('\\n'))\n",
    "\n",
    "textfalse = ''.join(ch for ch in textfalse if ch not in exclude)\n",
    "\n",
    "textfalse = textfalse.split(' ')\n",
    "\n",
    "for t in textfalse:\n",
    "    term = t.lower()\n",
    "    if term not in setfalse:\n",
    "        setfalse[term] = 1\n",
    "    else:\n",
    "        setfalse[term] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set2 = []\n",
    "for k,v in setfalse.items():\n",
    "    if v==1:\n",
    "        set2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setright = {}\n",
    "textright = ''.join(textright.split('\\n'))\n",
    "\n",
    "textright = ''.join(ch for ch in textright if ch not in exclude)\n",
    "\n",
    "textright = textright.split(' ')\n",
    "\n",
    "for t in textright:\n",
    "    term = t.lower()\n",
    "    if term not in setright:\n",
    "        setright[term] = 1\n",
    "    else:\n",
    "        setright[term] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set1 = []\n",
    "for k,v in setright.items():\n",
    "    if v==1:\n",
    "        set1.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['played',\n",
       " 'kitchen',\n",
       " 'up',\n",
       " 'rebranded',\n",
       " 'courses',\n",
       " 'allowed',\n",
       " 'highlighted',\n",
       " 'interesting',\n",
       " 'personally',\n",
       " 'olive',\n",
       " 'risotto',\n",
       " 'recognition',\n",
       " 'defining',\n",
       " 'satisfaction',\n",
       " 'you',\n",
       " 'indulge',\n",
       " 'also',\n",
       " 'beneath',\n",
       " 'choose',\n",
       " 'single',\n",
       " 'rather',\n",
       " 'plating',\n",
       " 'gem',\n",
       " 'entrees',\n",
       " 'an',\n",
       " 'stripside',\n",
       " 'thigh',\n",
       " 'cream',\n",
       " 'group',\n",
       " 'bright',\n",
       " 'arriving',\n",
       " 'undersaucing',\n",
       " 'order',\n",
       " 'tasting',\n",
       " 'known',\n",
       " 'around',\n",
       " 'lightest',\n",
       " 'round',\n",
       " 'indicated',\n",
       " 'family',\n",
       " 'marketing',\n",
       " 'lustinducing',\n",
       " 'types',\n",
       " 'upper',\n",
       " 'familystyle',\n",
       " 'playing',\n",
       " 'show',\n",
       " 'friendly',\n",
       " 'coated',\n",
       " 'punctuated',\n",
       " 'fonduta',\n",
       " 'reportedly',\n",
       " 'seemingly',\n",
       " 'agnolotti',\n",
       " 'past',\n",
       " 'cursive',\n",
       " 'music',\n",
       " 'seared',\n",
       " 'steak',\n",
       " 'quintet',\n",
       " 'yearnot',\n",
       " 'flavors',\n",
       " 'any',\n",
       " 'mozzarella',\n",
       " 'lightly',\n",
       " 'its',\n",
       " 'brand',\n",
       " 'focaccia',\n",
       " 'spicy',\n",
       " 'pervasive',\n",
       " 'gnocchi',\n",
       " 'putting',\n",
       " 'miles',\n",
       " 'hash',\n",
       " 'know',\n",
       " 'progressing',\n",
       " 'garlic',\n",
       " 'undoubtedly',\n",
       " 'strong',\n",
       " 'days',\n",
       " 'al',\n",
       " 'bone',\n",
       " 'out',\n",
       " 'fettuccini',\n",
       " 'tucked',\n",
       " 'wait',\n",
       " 'large',\n",
       " 'lacked',\n",
       " 'already',\n",
       " 'size',\n",
       " 'televisions',\n",
       " 'crispy',\n",
       " 'seating',\n",
       " 'beige',\n",
       " 'name',\n",
       " 'things',\n",
       " 'rounds',\n",
       " 'go',\n",
       " 'trend',\n",
       " 'puree',\n",
       " 'stuffed',\n",
       " 'semifreddo',\n",
       " 'feigning',\n",
       " 'breast',\n",
       " 'cauliflower',\n",
       " 'wildcats',\n",
       " 'toque',\n",
       " 'presenting',\n",
       " 'smile',\n",
       " 'threatened',\n",
       " 'float',\n",
       " 'diamond',\n",
       " 'acted',\n",
       " 'superlative',\n",
       " 'phrases',\n",
       " 'achieved',\n",
       " 'traditional',\n",
       " 'funk',\n",
       " 'staples',\n",
       " 'dictated',\n",
       " 'clearly',\n",
       " 'lengthy',\n",
       " 'months',\n",
       " 'sauces',\n",
       " 'marys',\n",
       " 'concepts',\n",
       " 'textbooks',\n",
       " 'musky',\n",
       " 'nearby',\n",
       " 'few',\n",
       " 'cocoa',\n",
       " 'each',\n",
       " 'buco',\n",
       " 'served',\n",
       " 'thanks',\n",
       " 'direction',\n",
       " 'decadent',\n",
       " 'discourses',\n",
       " 'option',\n",
       " 'salad',\n",
       " 'discover',\n",
       " 'composition',\n",
       " 'rarity',\n",
       " 'coffee',\n",
       " 'now',\n",
       " 'amongst',\n",
       " 'ranks',\n",
       " 'only',\n",
       " 'help',\n",
       " 'fully',\n",
       " 'ive',\n",
       " 'every',\n",
       " 'ripatelli',\n",
       " 'marinara',\n",
       " 'notes',\n",
       " 'perhaps',\n",
       " 'house',\n",
       " 'accentuate',\n",
       " 'arancini',\n",
       " 'leg',\n",
       " 'diversity',\n",
       " 'heritage',\n",
       " 'spring',\n",
       " 'three',\n",
       " 'decorating',\n",
       " 'spaces',\n",
       " 'when',\n",
       " 'showing',\n",
       " 'housepreviously',\n",
       " 'least',\n",
       " '900pm',\n",
       " 'hide',\n",
       " 'hour',\n",
       " 'renditions',\n",
       " 'topped',\n",
       " 'american',\n",
       " 'down',\n",
       " 'spoon',\n",
       " 'ohioan',\n",
       " 'greeted',\n",
       " 'meatballs',\n",
       " 'passion',\n",
       " 'specifically',\n",
       " 'joke',\n",
       " 'descriptions',\n",
       " 'we',\n",
       " 'last',\n",
       " 'enough',\n",
       " 'sat',\n",
       " 'next',\n",
       " 'serious',\n",
       " 'drinks',\n",
       " 'prepared',\n",
       " 'full',\n",
       " 'badgers',\n",
       " 'pasta',\n",
       " 'seen',\n",
       " 'vegetal',\n",
       " 'passionate',\n",
       " 'original',\n",
       " 'dente',\n",
       " 'mr',\n",
       " 'stories',\n",
       " 'question',\n",
       " 'chris',\n",
       " 'considered',\n",
       " 'plate',\n",
       " 'mere',\n",
       " 'gold',\n",
       " 'sourcing',\n",
       " 'filling',\n",
       " 'mushrooms',\n",
       " 'oil',\n",
       " 'upscaled',\n",
       " 'offering',\n",
       " 'fan',\n",
       " 'myself',\n",
       " 'favorites',\n",
       " 'friend',\n",
       " 'highly',\n",
       " 'lines',\n",
       " 'conceptualized',\n",
       " 'lasagna',\n",
       " 'whimsy',\n",
       " 'hunger',\n",
       " 'veal',\n",
       " 'beyond',\n",
       " 'people',\n",
       " 'others',\n",
       " 'inside',\n",
       " 'sundried',\n",
       " 'decanted',\n",
       " 'some',\n",
       " 'overwhelmat',\n",
       " 'discussed',\n",
       " 'once',\n",
       " 'story',\n",
       " 'breadings',\n",
       " 'carbonara',\n",
       " 'them',\n",
       " 'blossoms',\n",
       " 'lightstarting',\n",
       " 'five',\n",
       " 'upcoming',\n",
       " 'white',\n",
       " 'free',\n",
       " 'caprese',\n",
       " 'dÃ©cor',\n",
       " 'main',\n",
       " 'other',\n",
       " 'michael',\n",
       " 'being',\n",
       " 'moments',\n",
       " 'about',\n",
       " 'look',\n",
       " 'date',\n",
       " 'performed',\n",
       " 'still',\n",
       " 'first',\n",
       " 'destination',\n",
       " 'finally',\n",
       " 'entirely',\n",
       " 'lingering',\n",
       " 'becomes',\n",
       " 'melding',\n",
       " 'careful',\n",
       " 'celebrated',\n",
       " 'native',\n",
       " 'rest',\n",
       " 'familiar',\n",
       " 'sausage',\n",
       " 'wrapped',\n",
       " 'found',\n",
       " 'nearly',\n",
       " 'cut',\n",
       " 'effortlessly',\n",
       " 'onda',\n",
       " 'toques',\n",
       " 'attempted',\n",
       " 'front',\n",
       " 'surprising',\n",
       " 'far',\n",
       " 'moving',\n",
       " 'pastry',\n",
       " 'style',\n",
       " 'glazed',\n",
       " 'blended',\n",
       " 'housemade',\n",
       " 'linen',\n",
       " 'polenta',\n",
       " 'textbook',\n",
       " 'bartender',\n",
       " 'hidden',\n",
       " 'level',\n",
       " 'belowrepeatedly',\n",
       " 'back',\n",
       " 'octopus',\n",
       " 'arrived',\n",
       " 'bar',\n",
       " 'unique',\n",
       " 'delicate',\n",
       " 'contributions',\n",
       " 'couldnt',\n",
       " 'praise',\n",
       " 'proved',\n",
       " 'creativity',\n",
       " 'seconds',\n",
       " 'old',\n",
       " 'fluffy',\n",
       " 'seems',\n",
       " 'bit',\n",
       " 'overheaddivided',\n",
       " 'sing',\n",
       " 'vision',\n",
       " 'into',\n",
       " 'supple',\n",
       " 'what',\n",
       " 'sporting',\n",
       " 'gm',\n",
       " 'chicken',\n",
       " 'or',\n",
       " 'becoming',\n",
       " 'menu',\n",
       " 'selected',\n",
       " 'rendering',\n",
       " 'laplaca',\n",
       " 'leplaca',\n",
       " 'tiramisu',\n",
       " 'friends',\n",
       " 'well',\n",
       " 'fall',\n",
       " 'although',\n",
       " 'cheeses',\n",
       " 'parm',\n",
       " 'these',\n",
       " 'walls',\n",
       " 'operating',\n",
       " 'buffalo',\n",
       " 'silent',\n",
       " 'corner',\n",
       " 'twice',\n",
       " 'proteins',\n",
       " 'eschewing',\n",
       " 'branzino',\n",
       " 'mid2014',\n",
       " 'words',\n",
       " 'starter',\n",
       " 'partys',\n",
       " 'duo',\n",
       " 'likes',\n",
       " 'roulade',\n",
       " 'sin',\n",
       " 'lamb',\n",
       " 'pungent',\n",
       " 'spin',\n",
       " 'crabcakes',\n",
       " 'closer',\n",
       " 'loungelarge',\n",
       " 'realized',\n",
       " 'range',\n",
       " 'under',\n",
       " 'casino',\n",
       " 'opposed',\n",
       " 'they',\n",
       " 'squash',\n",
       " 'melted',\n",
       " 'widenoodle',\n",
       " 'fresh',\n",
       " 'aromatic',\n",
       " 'suggest',\n",
       " 'over',\n",
       " 'ask',\n",
       " 'flawlessly',\n",
       " 'mozzarellaadmittedly',\n",
       " 'espresso',\n",
       " 'savvy',\n",
       " '630',\n",
       " 'total',\n",
       " 'turning',\n",
       " 'concluded',\n",
       " 'osso',\n",
       " 'something',\n",
       " 'there',\n",
       " 'mirage',\n",
       " 'grassy',\n",
       " 'follow',\n",
       " 'wine',\n",
       " 'dislikes',\n",
       " 'design',\n",
       " 'began']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will write multi-step MapReduce jobs Python using [mrjob](https://pythonhosted.org/mrjob/). First, we will test it on our local machine and then run it on Amazon AWS.\n",
    "\n",
    "We will use the [Yelp reviews dataset](https://drive.google.com/a/bu.edu/file/d/0B4bdB5WPHGsqcmJMNmxzQmQ3aTQ/view?usp=sharing) from Assignment 2.\n",
    "\n",
    "This assignment should be completed **individually**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply for AWS Educate Account (do this now!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is extremely important that you apply for an \"AWS Educate\" account right away to get $100 free credit, and verify that the credit has been properly applied to your account.\n",
    "\n",
    "* Go to https://www.awseducate.com/Application\n",
    "* Choose **Student** and click **Next**\n",
    "* Fill out the application\n",
    "\n",
    "We recommend selecting an AWS Educate Starter Account. If, instead, you want to use an AWS Account ID, it is important that you set up a billing alarm on AWS to notify you when your credits are running low.\n",
    "\n",
    "Remember to shut down **everything** when you're done with the instances, or you may get surprising bills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a mapper and reducer that yield the total uses of a word across all reviews. (**5pts**)\n",
    "\n",
    "In the map step, we want to extract words from the text of reviews. Then, count the words in each review. In the reduce step, summarize all the counts by taking the sum.\n",
    "\n",
    "A recap of how to use mrjob: https://pythonhosted.org/mrjob/guides/quickstart.html\n",
    "\n",
    "Note, when you are testing it on a local machine, you may only want to run a subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import JSONValueProtocol\n",
    "import re, string\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "class MRCount(MRJob):\n",
    "\n",
    "    #INPUT_PROTOCOL = JSONProtocol\n",
    "    INPUT_PROTOCOL = JSONValueProtocol\n",
    "    OUTPUT_PROTOCOL = JSONValueProtocol\n",
    "\n",
    "    def mapper(self, key, review):\n",
    "\n",
    "        # punctuation set\n",
    "        exclude = set(string.punctuation)\n",
    "\n",
    "        # remove the new line character from the string\n",
    "        text = ''.join(review['text'].split('\\n'))\n",
    "\n",
    "        # remove all puncuation from the string \n",
    "        text = ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "        # split the text\n",
    "        text = text.split(' ')\n",
    "\n",
    "        for term in text: \n",
    "            yield term.lower(), 1 \n",
    "\n",
    "        \n",
    "\n",
    "    def reducer(self, term, counts):\n",
    "        yield None, {'term': term, 'count': sum(counts)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Unique Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a multi-step map reduce that yield the review_id with text containing the maximum number of unique words across all reviews. (**15pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob \n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import JSONValueProtocol\n",
    "import re, string\n",
    "\n",
    "# Write a multi-step map reduce that yield the review_id with text \n",
    "# containing the maximum number of unique words across all reviews.\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "    INPUT_PROTOCOL = JSONValueProtocol\n",
    "    OUTPUT_PROTOCOL = JSONValueProtocol\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_id_words),\n",
    "                   #combiner=self.combiner_count_words,\n",
    "                   #reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_id_words),\n",
    "            MRStep(reducer=self.reducer_unique_word_list),\n",
    "            MRStep(reducer=self.reducer_find_max_unique_review)\n",
    "        ]\n",
    "\n",
    "    def mapper_id_words(self, key, review):\n",
    "    \texclude = set(string.punctuation)\n",
    "\n",
    "    \treview_id = review['review_id']\n",
    "\n",
    "    \ttext = ''.join(review['text'].split('\\n'))\n",
    "\n",
    "    \ttext = ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    \ttext = text.split(' ')\n",
    "\n",
    "    \tfor term in text:\n",
    "    \t\t# yield (id, word), 1\n",
    "            \n",
    "            if(term!=\"\"):\n",
    "                #print(review_id, term)\n",
    "                yield (review_id, term.lower()),1\n",
    "\n",
    "    def reducer_id_words(self, key, counts):\n",
    "        c = sum(counts)\n",
    "        if c == 1:\n",
    "            yield key[0], c\n",
    "\n",
    "    def reducer_unique_word_list(self, key, counts):\n",
    "        c = sum(counts)\n",
    "        #print(key,c)\n",
    "        yield None, (c,key)\n",
    "\n",
    "    def reducer_find_max_unique_review(self, _, counts):\n",
    "        yield max(counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 3: User Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a map reduce that measures the Jaccard similarity of users based on the businesses reviewed, and find users with >= 0.5 similarity. (**15pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob \n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import JSONValueProtocol\n",
    "import re, string\n",
    "\n",
    "# Write a map reduce that measures the Jaccard similarity of users based on \n",
    "# the businesses reviewed, and find users with >= 0.5 similarity. \n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    INPUT_PROTOCOL = JSONValueProtocol\n",
    "    OUTPUT_PROTOCOL = JSONValueProtocol\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_uid_bid),\n",
    "                   #combiner=self.combiner_count_words,\n",
    "                   #reducer=self.reducer_uid_list),\n",
    "            MRStep(reducer=self.reducer_uid_bs_list),\n",
    "            MRStep(reducer=self.reducer_bid_to_uid),\n",
    "            MRStep(reducer=self.reducer_pair),\n",
    "            MRStep(reducer=self.reducer_remove_duplicate)\n",
    "        ]\n",
    "\n",
    "    def mapper_uid_bid(self, key, review):\n",
    "        user_b_list = {}\n",
    "        user_id = review['user_id']\n",
    "        business_id = review['business_id']\n",
    "\n",
    "        # update the dictionary\n",
    "        if user_id in user_b_list:\n",
    "            user_b_list[user_id].append(business_id)\n",
    "        else:\n",
    "            l = []\n",
    "            l.append(business_id)\n",
    "            user_b_list[user_id] = l\n",
    "        \n",
    "        yield user_id, business_id\n",
    "\n",
    "\n",
    "    def reducer_uid_bs_list(self, user_id, business_id_list):\n",
    "        bid_list = []\n",
    "        for bid in business_id_list:\n",
    "            bid_list.append(bid)\n",
    "\n",
    "        yield user_id, bid_list\n",
    "\n",
    "\n",
    "    def reducer_bid_to_uid(self, user_id, business_id_list):\n",
    "        bid_list = []\n",
    "        for item in business_id_list:\n",
    "            for bid in item:\n",
    "                bid_list.append(bid)\n",
    "\n",
    "        for bid in bid_list:\n",
    "\n",
    "            yield bid, (user_id, bid_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def reducer_pair(self, bid, li):\n",
    "        business_list = []\n",
    "        for x in li:\n",
    "            business_list.append(x)\n",
    "\n",
    "        length = len(business_list)\n",
    "\n",
    "        # sorte the business_list, prevent when do the double\n",
    "        business_list = sorted(business_list, key=lambda x: x[0])\n",
    "\n",
    "        i = 0\n",
    "        for i in range(0,length):\n",
    "            j = i+1\n",
    "            if j<length:\n",
    "                for k in range(j,length):\n",
    "                    #print(business_list[i])\n",
    "                    #print(business_list[i])\n",
    "                    s1 = set(business_list[i][1])\n",
    "                    s2 = set(business_list[k][1])\n",
    "\n",
    "                    score = len(s1.intersection(s2))/len(s1.union(s2))\n",
    "                    pair1 = business_list[i][0]\n",
    "                    pair2 = business_list[k][0]\n",
    "\n",
    "                    #yield set((pair1,pair2)), {'pair':pair1+' '+pair2, 'score':score}\n",
    "                    if score>0.5:\n",
    "                        yield (pair1,pair2), score\n",
    "\n",
    "    def reducer_remove_duplicate(self, pair, score):\n",
    "        l = []\n",
    "        for x in score:\n",
    "            l.append(x)\n",
    "        yield None, {'pair':pair, 'score':l[0]}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 4: Run on Amazon Elastic MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Amazon Simple Storage Service (S3). To create an S3 bucket, sign into the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3. Click **Create Bucket** on the top left. After you have created your bucket, click **Upload** and upload yelp_academic_dataset_review.json in your bucket.\n",
    "\n",
    "To allow mrjob to run your code on Amazon EMR, first you need to configure your AWS and SSH credentials: http://pythonhosted.org/mrjob/guides/emr-quickstart.html\n",
    "\n",
    "The following command will read in yelp_academic_dataset_review.json from your S3 bucket and store the output in a directory called \"output\" in your S3 bucket (you can view your S3 bucket at https://console.aws.amazon.com/s3). The output will also be streamed back to your local machine.\n",
    "\n",
    "`python unique_review.py -r emr s3://name-of-your-bucket/yelp_academic_dataset_review.json --output-dir=s3://name-of-your-bucket/output/`\n",
    "\n",
    "By default, mrjob runs a single m1.medium, which is a cheap but not very powerful instance type. To get more performance out of your job, you can eiher add more instances, use more powerful instances, or both. Amazon bills you for the full hour even if your cluster only lasts for a few minutes.\n",
    "\n",
    "The basic way to control type and number of instances is with `instance_type` and `num_core_instances` options on the command line like this:\n",
    "\n",
    "`--instance_type m1.medium --num-core-instances 4`\n",
    "\n",
    "or adding to mrjob.conf that you created earlier:\n",
    "\n",
    "`runners:\n",
    "  emr:\n",
    "    instance_type: m1.medium\n",
    "    num_core_instances: 4\n",
    "`\n",
    "\n",
    "You can see the jobs you run here: http://console.aws.amazon.com/elasticmapreduce/\n",
    "\n",
    "Here are a few more links that you may find useful:\n",
    "* https://aws.amazon.com/emr/pricing/\n",
    "* http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html#vpc-only-instance-types\n",
    "* http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-troubleshoot-failed.html\n",
    "* http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-troubleshoot-slow.html\n",
    "\n",
    "Submit the output of your 3 tasks running on Amazon EMR. (**15pts**)\n",
    "\n",
    "You can redirect the output to a file with the following:\n",
    "\n",
    "`python unique_review.py -r emr s3://name-of-your-bucket/yelp_academic_dataset_review.json --output-dir=s3://name-of-your-bucket/output/ > unique_review.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
